<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>大模型评估数据集 | Notes</title><meta name="author" content="EeyoreLee"><meta name="copyright" content="EeyoreLee"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="基础常识推理 BoolQ     BoolQ is a question answering dataset for yes&#x2F;no questions containing 15942 examples. These questions are naturally occurring ---they are generated in unprompted and unconstrained set">
<meta property="og:type" content="article">
<meta property="og:title" content="大模型评估数据集">
<meta property="og:url" content="https://eeyorelee.github.io/llm-benchmarks/index.html">
<meta property="og:site_name" content="Notes">
<meta property="og:description" content="基础常识推理 BoolQ     BoolQ is a question answering dataset for yes&#x2F;no questions containing 15942 examples. These questions are naturally occurring ---they are generated in unprompted and unconstrained set">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://eeyorelee.github.io/img/avatar.jpg">
<meta property="article:published_time" content="2023-07-24T10:35:36.000Z">
<meta property="article:modified_time" content="2024-10-23T16:05:03.952Z">
<meta property="article:author" content="EeyoreLee">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://eeyorelee.github.io/img/avatar.jpg"><link rel="shortcut icon" href="/img/fa.png"><link rel="canonical" href="https://eeyorelee.github.io/llm-benchmarks/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Error',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '大模型评估数据集',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-10-23 16:05:03'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">22</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">6</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background: transparent"><nav id="nav"><span id="blog-info"><a href="/" title="Notes"><span class="site-name">Notes</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">大模型评估数据集</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-07-24T10:35:36.000Z" title="Created 2023-07-24 10:35:36">2023-07-24</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2024-10-23T16:05:03.952Z" title="Updated 2024-10-23 16:05:03">2024-10-23</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/">数据科学</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="大模型评估数据集"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1>基础常识推理</h1>
<h2 id="boolq"><a target="_blank" rel="noopener" href="https://huggingface.co/datasets/boolq">BoolQ</a></h2>
<div align=center> <img src="/img/llm-benchmarks/BoolQ.png" width="600"> </div> 
BoolQ is a question answering dataset for yes/no questions containing 15942 examples. These questions are naturally occurring ---they are generated in unprompted and unconstrained settings. Each example is a triplet of (question, passage, answer), with the title of the page as optional additional context. The text-pair classification setup is similar to existing natural language inference tasks.
<h2 id="piqa-physical-interaction-question-answering"><a target="_blank" rel="noopener" href="https://huggingface.co/datasets/piqa">PIQA(Physical Interaction: Question Answering)</a></h2>
<div align=center> <img src="/img/llm-benchmarks/PIQA.png" width="600"> </div> 
The dataset contains 16,000 examples for training, 2,000 for development and 3,000 for testing.
<ul>
<li>goal: the question which requires physical commonsense to be answered correctly</li>
<li>sol1: the first solution</li>
<li>sol2: the second solution</li>
<li>label: the correct solution. 0 refers to sol1 and 1 refers to sol2</li>
</ul>
<h2 id="siqa-social-interaction-qa"><a target="_blank" rel="noopener" href="https://leaderboard.allenai.org/socialiqa/submissions/get-started">SIQA(Social Interaction QA)</a></h2>
<p>We introduce Social IQa: Social Interaction QA, a new question-answering benchmark for testing social commonsense intelligence. Contrary to many prior benchmarks that focus on physical or taxonomic knowledge, Social IQa focuses on reasoning about people’s actions and their social implications. For example, given an action like “Jesse saw a concert” and a question like “Why did Jesse do this?”, humans can easily infer that Jesse wanted “to see their favorite performer” or “to enjoy the music”, and not “to see what’s happening inside” or “to see if it works”. The actions in Social IQa span a wide variety of social situations, and answer candidates contain both human-curated answers and adversarially-filtered machine-generated candidates. Social IQa contains over 37,000 QA pairs for evaluating models’ abilities to reason about the social implications of everyday events and situations.</p>
<p>The data is encoded in JSON Lines Format:</p>
<ul>
<li>context: A context describing a sitation</li>
<li>question: A question probing commonsense reasoning about motivation, emotional reactions etc.</li>
<li>answerA: The first answer choice</li>
<li>answerB: The second answer choice</li>
<li>answerC: The third answer choice</li>
</ul>
<h2 id="hellaswag"><a target="_blank" rel="noopener" href="https://rowanzellers.com/hellaswag/">HellaSwag</a></h2>
<p>专门针对欺骗机器的推理题。研究基于场景的常识推理的数据集。它包含70,000个关于场景的多项选择问题：每个问题来自两个领域中的一个——activitynet或wikihow，并提供四个答案选项，描述了场景中接下来可能发生的事情。正确答案是下一个事件的（真实）句子；而另外三个错误答案是通过对抗生成并经过人工验证的，旨在欺骗机器而不是人类。</p>
<h2 id="winogrande"><a target="_blank" rel="noopener" href="https://huggingface.co/datasets/winogrande">WinoGrande</a></h2>
<div align=center> <img src="/img/llm-benchmarks/WinoGrande.png" width="600"> </div> 
WinoGrande is a new collection of 44k problems, inspired by Winograd Schema Challenge (Levesque, Davis, and Morgenstern 2011), but adjusted to improve the scale and robustness against the dataset-specific bias. Formulated as a fill-in-a-blank task with binary options, the goal is to choose the right option for a given sentence which requires commonsense reasoning.
<h2 id="arc-e-arc-c"><a target="_blank" rel="noopener" href="https://allenai.org/data/arc">ARC-e &amp; ARC-c</a></h2>
<p>The ARC dataset consists of 7,787 science exam questions drawn from a variety of sources, including science questions provided under license by a research partner affiliated with AI2. These are text-only, English language exam questions that span several grade levels as indicated in the files. Each question has a multiple choice structure (typically 4 answer options). The questions are sorted into a Challenge Set of 2,590 “hard” questions (those that both a retrieval and a co-occurrence method fail to answer correctly) and an Easy Set of 5,197 questions. Each are pre-split into Train, Development, and Test sets as follows:</p>
<ul>
<li>Challenge Train: 1,119</li>
<li>Challenge Dev: 299</li>
<li>Challenge Test: 1,172</li>
<li>Easy Train: 2,251</li>
<li>Easy Dev: 570</li>
<li>Easy Test: 2,376</li>
</ul>
<h2 id="obqa"><a target="_blank" rel="noopener" href="https://allenai.org/data/open-book-qa">OBQA</a></h2>
<p>OpenBookQA is a new kind of question-answering dataset modeled after open book exams for assessing human understanding of a subject. It consists of 5,957 multiple-choice elementary-level science questions (4,957 train, 500 dev, 500 test), which probe the understanding of a small “book” of 1,326 core science facts and the application of these facts to novel situations. For training, the dataset includes a mapping from each question to the core science fact it was designed to probe. Answering OpenBookQA questions requires additional broad common knowledge, not contained in the book. The questions, by design, are answered incorrectly by both a retrieval-based algorithm and a word co-occurrence algorithm. Strong neural baselines achieve around 50% on OpenBookQA, leaving a large gap to the 92% accuracy of crowd-workers.</p>
<p>Additionally, we provide 5,167 crowd-sourced common knowledge facts, and an expanded version of the train/dev/test questions where each question is associated with its originating core fact, a human accuracy score, a clarity score, and an anonymized crowd-worker ID (in the “Additional” folder).</p>
<h1>Closed-book Question Answering</h1>
<p>原数据集是可以参考一个evidence，该项为了评估大模型zero-shot，不加入evidence</p>
<h2 id="natural-questions"><a target="_blank" rel="noopener" href="https://ai.google.com/research/NaturalQuestions">Natural Questions</a></h2>
<p>Natural Questions Dataset is a question answering dataset. Questions consist of real anonymized, aggregated queries issued to the Google search engine. An annotator is presented with a question along with a Wikipedia page from the top 5 search results, and annotates a long answer (typically a paragraph) and a short answer (one or more entities) if present on the page, or marks null if no long/short answer is present. The public release consists of 307,373 training examples with single annotations, 7,830 examples with 5-way annotations for development data, and a further 7,842 examples 5-way annotated sequestered as test data.<br>
In total, annotators identify a long answer for 49% of the examples, and short answer spans or a yes/no answer for 36% of the examples.Annotators identify long answers by selecting the smallest HTML bounding box that contains all of the information required to answer the question. These are mostly paragraphs (73%). The remainder are made up of tables (19%), table rows (1%), lists (3%), or list items (3%).</p>
<h2 id="triviaqa"><a target="_blank" rel="noopener" href="http://nlp.cs.washington.edu/triviaqa/">TriviaQA</a></h2>
<div align=center> <img src="/img/llm-benchmarks/TriviaQA.png" width="600"> </div> 
<p>TriviaQA is a reading comprehension dataset containing over 650K question-answer-evidence triples. TriviaQA includes 95K question-answer pairs authored by trivia enthusiasts and independently gathered evidence documents, six per question on average, that provide high quality distant supervision for answering the questions.</p>
<h1>阅读理解</h1>
<h2 id="race"><a target="_blank" rel="noopener" href="https://www.cs.cmu.edu/~glai1/data/race/">RACE</a></h2>
<div align=center> <img src="/img/llm-benchmarks/RACE.png" width="600"> </div> 
<p>The ReAding Comprehension dataset from Examinations (RACE) dataset is a machine reading comprehension dataset consisting of 27,933 passages and 97,867 questions from English exams, targeting Chinese students aged 12-18. RACE consists of two subsets, RACE-M and RACE-H, from middle school and high school exams, respectively. RACE-M has 28,293 questions and RACE-H has 69,574. Each question is associated with 4 candidate answers, one of which is correct. The data generation process of RACE differs from most machine reading comprehension datasets - instead of generating questions and answers by heuristics or crowd-sourcing, questions in RACE are specifically designed for testing human reading skills, and are created by domain experts.</p>
<h1>数学推理</h1>
<h2 id="math"><a target="_blank" rel="noopener" href="https://github.com/hendrycks/math/">MATH</a></h2>
<div align=center> <img src="/img/llm-benchmarks/MATH.png" width="600"> </div> 
<p>MATH is a new dataset of 12,500 challenging competition mathematics problems. Each problem in MATH has a full step-by-step solution which can be used to teach models to generate answer derivations and explanations.</p>
<h2 id="gsm8k"><a target="_blank" rel="noopener" href="https://github.com/openai/grade-school-math">GSM8k</a></h2>
<div align=center> <img src="/img/llm-benchmarks/GSM8k.png" width="600"> </div> 
<p>GSM8K is a dataset of 8.5K high quality linguistically diverse grade school math word problems created by human problem writers. The dataset is segmented into 7.5K training problems and 1K test problems. These problems take between 2 and 8 steps to solve, and solutions primarily involve performing a sequence of elementary calculations using basic arithmetic operations (+ − ×÷) to reach the final answer. A bright middle school student should be able to solve every problem. It can be used for multi-step mathematical reasoning.</p>
<h1>代码生成</h1>
<h2 id="humaneval"><a target="_blank" rel="noopener" href="https://github.com/openai/human-eval">HumanEval</a></h2>
<div align=center> <img src="/img/llm-benchmarks/HumanEval.png" width="600"> </div> 
<p>This is an evaluation harness for the HumanEval problem solving dataset described in the paper “Evaluating Large Language Models Trained on Code”. It used to measure functional correctness for synthesizing programs from docstrings. It consists of 164 original programming problems, assessing language comprehension, algorithms, and simple mathematics, with some comparable to simple software interview questions.</p>
<h2 id="mbpp"><a target="_blank" rel="noopener" href="https://huggingface.co/datasets/mbpp">MBPP</a></h2>
<div align=center> <img src="/img/llm-benchmarks/MBPP.png" width="600"> </div> 
<p>The benchmark consists of around 1,000 crowd-sourced Python programming problems, designed to be solvable by entry-level programmers, covering programming fundamentals, standard library functionality, and so on. Each problem consists of a task description, code solution and 3 automated test cases.</p>
<h1>Massive Multitask Language Understanding</h1>
<h2 id="mmlu"><a target="_blank" rel="noopener" href="https://github.com/hendrycks/test">MMLU</a></h2>
<div align=center> <img src="/img/llm-benchmarks/MMLU.png" width="600"> </div> 
<p>MMLU (Massive Multitask Language Understanding) is a new benchmark designed to measure knowledge acquired during pretraining by evaluating models exclusively in zero-shot and few-shot settings. This makes the benchmark more challenging and more similar to how we evaluate humans. The benchmark covers 57 subjects across STEM, the humanities, the social sciences, and more. It ranges in difficulty from an elementary level to an advanced professional level, and it tests both world knowledge and problem solving ability. Subjects range from traditional areas, such as mathematics and history, to more specialized areas like law and ethics. The granularity and breadth of the subjects makes the benchmark ideal for identifying a model’s blind spots.</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://eeyorelee.github.io">EeyoreLee</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://eeyorelee.github.io/llm-benchmarks/">https://eeyorelee.github.io/llm-benchmarks/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="/img/avatar.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/mixed-precision-training/" title="混合精度训练"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Previous</div><div class="prev_info">混合精度训练</div></div></a></div><div class="next-post pull-right"><a href="/gpt/" title="GPT Series"><img class="cover" src="/img/ChatGPT.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next</div><div class="next_info">GPT Series</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">EeyoreLee</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">22</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">6</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/EeyoreLee"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">基础常识推理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#boolq"><span class="toc-number">1.1.</span> <span class="toc-text">BoolQ</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#piqa-physical-interaction-question-answering"><span class="toc-number">1.2.</span> <span class="toc-text">PIQA(Physical Interaction: Question Answering)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#siqa-social-interaction-qa"><span class="toc-number">1.3.</span> <span class="toc-text">SIQA(Social Interaction QA)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#hellaswag"><span class="toc-number">1.4.</span> <span class="toc-text">HellaSwag</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#winogrande"><span class="toc-number">1.5.</span> <span class="toc-text">WinoGrande</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#arc-e-arc-c"><span class="toc-number">1.6.</span> <span class="toc-text">ARC-e &amp; ARC-c</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#obqa"><span class="toc-number">1.7.</span> <span class="toc-text">OBQA</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">Closed-book Question Answering</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#natural-questions"><span class="toc-number">2.1.</span> <span class="toc-text">Natural Questions</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#triviaqa"><span class="toc-number">2.2.</span> <span class="toc-text">TriviaQA</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">阅读理解</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#race"><span class="toc-number">3.1.</span> <span class="toc-text">RACE</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">数学推理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#math"><span class="toc-number">4.1.</span> <span class="toc-text">MATH</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#gsm8k"><span class="toc-number">4.2.</span> <span class="toc-text">GSM8k</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">代码生成</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#humaneval"><span class="toc-number">5.1.</span> <span class="toc-text">HumanEval</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#mbpp"><span class="toc-number">5.2.</span> <span class="toc-text">MBPP</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">6.</span> <span class="toc-text">Massive Multitask Language Understanding</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#mmlu"><span class="toc-number">6.1.</span> <span class="toc-text">MMLU</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/model-es-performance-optimization/" title="记：一次接口性能优化（cpu模型推理 + ES)">记：一次接口性能优化（cpu模型推理 + ES)</a><time datetime="2024-08-22T19:38:04.000Z" title="Created 2024-08-22 19:38:04">2024-08-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/paged-attention/" title="PagedAttention">PagedAttention</a><time datetime="2024-08-20T19:23:32.000Z" title="Created 2024-08-20 19:23:32">2024-08-20</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/kv-cache/" title="KV Cache">KV Cache</a><time datetime="2024-07-10T16:59:38.000Z" title="Created 2024-07-10 16:59:38">2024-07-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/closure/" title="闭包">闭包</a><time datetime="2024-01-02T14:57:12.000Z" title="Created 2024-01-02 14:57:12">2024-01-02</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/rlhf/" title="RLHF">RLHF</a><time datetime="2023-12-28T14:34:32.000Z" title="Created 2023-12-28 14:34:32">2023-12-28</time></div></div></div></div></div></div></main><footer id="footer" style="background: transparent"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By EeyoreLee</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading the Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>